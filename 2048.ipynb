{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "from IPython import display\n",
    "import time\n",
    "import math\n",
    "import cProfile\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_color(value):\n",
    "    if value <= 0:\n",
    "        return '#cdc1b4'\n",
    "    if value <= 2:\n",
    "        return '#eee4da'\n",
    "    if value <= 4:\n",
    "        return '#ede0c8'\n",
    "    if value <= 8:\n",
    "        return '#f2b179'\n",
    "    if value <= 16:\n",
    "        return '#f59563'\n",
    "    if value <= 32:\n",
    "        return '#f67c5f'\n",
    "    if value <= 64:\n",
    "        return '#f65e3b'\n",
    "    if value <= 128:\n",
    "        return '#edcf72'\n",
    "    if value <= 256:\n",
    "        return '#edcc61'\n",
    "    if value <= 512:\n",
    "        return '#edc850'\n",
    "    if value <= 1024:\n",
    "        return '#edc53f'\n",
    "    return '#ecc02e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class gameEnv():\n",
    "    def __init__(self):\n",
    "        self.size = 4\n",
    "        self.actions = 4\n",
    "        self.a = []\n",
    "        self.rendered = []\n",
    "        self.currReward = 0\n",
    "        self.cumReward = 0\n",
    "        self.reset()\n",
    "        self.won = False\n",
    "        self.movement = False\n",
    "        self.last_action = 0\n",
    "    \n",
    "    def reset(self):\n",
    "        arr = np.array([0 for i in range(16)])\n",
    "        self.a = arr.reshape([4,4])\n",
    "        self.addRandomOpen()\n",
    "        self.renderEnv()\n",
    "        self.currReward = 0\n",
    "        self.cumReward = 0\n",
    "        return self.a\n",
    "        \n",
    "    def addRandomOpen(self):\n",
    "        indices = np.asarray(np.where(self.a == 0)).T\n",
    "        choice = random.choice(indices)\n",
    "        if(np.random.rand(1)<.1):\n",
    "            self.a[choice[0]][choice[1]] = 4\n",
    "        else:\n",
    "            self.a[choice[0]][choice[1]] = 2\n",
    "    \n",
    "    def renderEnv(self):\n",
    "        arr = np.ones([4,4])\n",
    "        for i in range(16):\n",
    "            arr[i//4][i%4] = self.getColor(self.a[i//4][i%4])\n",
    "        return scipy.misc.imresize(arr[:,:],[84,84,1],interp='nearest')\n",
    "        \n",
    "    def getColor(self, val):\n",
    "        if(val == 0):\n",
    "            return 0\n",
    "        return math.log2(val) * 23\n",
    "    \n",
    "    def checkEnd(self):\n",
    "        if(len(np.where(self.a == 0)[0]) == 0):\n",
    "            for i in range(4):\n",
    "                self.move(i)\n",
    "                if(checkMove() == True):\n",
    "                    return False\n",
    "            return True\n",
    "#         if(len(np.where(self.a == 2048)[0]) != 0):\n",
    "#             if(self.won == False):\n",
    "#                 print(\"won the game!\")\n",
    "#                 self.won = True\n",
    "#             return True\n",
    "        return False\n",
    "    \n",
    "    # 0 - up, 1 - down, 2 - left, 3 - right\n",
    "    def move(self, action):\n",
    "        if(action == 0):\n",
    "            self.a = np.rot90(self.a,1)\n",
    "            self.a = self.mergeLeft(self.a)\n",
    "            self.a = np.rot90(self.a,3)\n",
    "        elif(action ==1):\n",
    "            self.a = np.rot90(self.a,3)\n",
    "            self.a = self.mergeLeft(self.a)\n",
    "            self.a = np.rot90(self.a,1)\n",
    "        elif(action == 2):\n",
    "            self.a = self.mergeLeft(self.a)\n",
    "        elif(action == 3):\n",
    "            self.a = np.rot90(self.a,2)\n",
    "            self.a = self.mergeLeft(self.a)\n",
    "            self.a = np.rot90(self.a,2)        \n",
    "        \n",
    "        if(self.movement == True):\n",
    "            self.addRandomOpen()\n",
    "            \n",
    "        return self.checkEnd()\n",
    "                        \n",
    "    def step(self, action):\n",
    "        self.last_action = action\n",
    "        done = self.move(action)\n",
    "        return self.renderEnv(),self.currReward,done\n",
    "    \n",
    "    def checkMove(self):\n",
    "        return self.movement\n",
    "        \n",
    "    def mergeLeft(self, arr):\n",
    "        self.currReward = 0\n",
    "        self.movement = False\n",
    "        for i in range(4):\n",
    "            for j in range(1, 4):\n",
    "                stop = 0\n",
    "                if arr[i][j] != 0:\n",
    "                    for k in range(stop, j):\n",
    "                        if(arr[i][k] == arr[i][j]):\n",
    "                            arr[i][k] = arr[i][k] * 2\n",
    "                            arr[i][j] = 0\n",
    "                            self.currReward += arr[i][k]\n",
    "                            stop = j\n",
    "                            self.movement = True\n",
    "                            break\n",
    "                        elif(arr[i][k] == 0):\n",
    "                            arr[i][k] = arr[i][j]\n",
    "                            arr[i][j] = 0\n",
    "                            self.movement = True\n",
    "                            break\n",
    "                            \n",
    "        self.cumReward += self.currReward\n",
    "        return arr\n",
    "    \n",
    "    def renderDisplay(self):\n",
    "        size_of_image = 8\n",
    "        font_size = 20\n",
    "        fig, ax = plt.subplots(figsize=(size_of_image+2, size_of_image))\n",
    "\n",
    "        for x in range(0, 4):\n",
    "            for y in range(0, 4):\n",
    "                ax.broken_barh([(x, 1)],\n",
    "                               (y, 1),\n",
    "                               facecolors=get_color(self.a[y][x]))\n",
    "                if(self.a[y][x] != 0):\n",
    "                    ax.annotate(str(self.a[y][x]), (x, y),\n",
    "                                xytext=((2*x + 1)/2, (2*y + 1) / 2),\n",
    "                                fontsize=font_size,\n",
    "                                horizontalalignment='center',\n",
    "                                verticalalignment='center')\n",
    "\n",
    "        # set range of plot grid\n",
    "        ax.set_ylim(4, 0)\n",
    "        ax.set_xlim(0, 5)\n",
    "\n",
    "        if self.last_action == 0:\n",
    "            # up\n",
    "            plt.arrow(4.5, 2.2, 0.0, -0.4, fc=\"k\", ec=\"k\", head_width=0.1, head_length=0.1)\n",
    "        elif self.last_action == 1:\n",
    "            # down\n",
    "            plt.arrow(4.5, 1.8, 0.0, 0.4, fc=\"k\", ec=\"k\", head_width=0.1, head_length=0.1)\n",
    "        elif self.last_action == 2:\n",
    "            # left\n",
    "            plt.arrow(4.8, 2.0, -0.4, 0.0, fc=\"k\", ec=\"k\", head_width=0.1, head_length=0.1)\n",
    "        elif self.last_action == 3:\n",
    "            # right\n",
    "            plt.arrow(4.3, 2.0, 0.4, 0.0, fc=\"k\", ec=\"k\", head_width=0.1, head_length=0.1)\n",
    "\n",
    "        ax.annotate(\"Score:\", (1, 1), xytext=(4.5, 0.5), fontsize=20,\n",
    "                   horizontalalignment='center', verticalalignment='center')\n",
    "        ax.annotate(str(self.cumReward), (1, 1), xytext=(4.5, 0.9), fontsize=20,\n",
    "                    horizontalalignment='center', verticalalignment='center')    \n",
    "\n",
    "        plt.axis('off')\n",
    "        ax.grid(True)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self,h_size,prev_states):        \n",
    "        #The network recieves a frame from the game, flattened into an array.\n",
    "        #It then resizes it and processes it through four convolutional layers.\n",
    "        self.imageIn = tf.placeholder(shape=[None,84,84,1],dtype=tf.float32)\n",
    "        self.conv1 = tf.contrib.layers.convolution2d( \\\n",
    "            inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n",
    "        self.conv2 = tf.contrib.layers.convolution2d( \\\n",
    "            inputs=self.conv1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding='VALID', biases_initializer=None)\n",
    "        self.conv3 = tf.contrib.layers.convolution2d( \\\n",
    "            inputs=self.conv2,num_outputs=64,kernel_size=[3,3],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        self.conv4 = tf.contrib.layers.convolution2d( \\\n",
    "            inputs=self.conv3,num_outputs=512,kernel_size=[7,7],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        \n",
    "        #We take the output from the final convolutional layer and split it into separate advantage and value streams.\n",
    "        self.streamAC,self.streamVC = tf.split(3,2,self.conv4)\n",
    "        self.streamA = tf.contrib.layers.flatten(self.streamAC)\n",
    "        self.streamV = tf.contrib.layers.flatten(self.streamVC)\n",
    "        self.AW = tf.Variable(tf.random_normal([h_size//2,env.actions]))\n",
    "        self.VW = tf.Variable(tf.random_normal([h_size//2,1]))\n",
    "        self.Advantage = tf.matmul(self.streamA,self.AW)\n",
    "        self.Value = tf.matmul(self.streamV,self.VW)\n",
    "        \n",
    "        #Then combine them together to get our final Q-values.\n",
    "        self.Qout = self.Value + tf.sub(self.Advantage,tf.reduce_mean(self.Advantage,reduction_indices=1,keep_dims=True))\n",
    "        self.predict = tf.argmax(self.Qout,1)\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions,env.actions,dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(tf.mul(self.Qout, self.actions_onehot), reduction_indices=1)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        self.loss = tf.reduce_mean(self.td_error)\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    \"\"\"Used to store experiences and samples randomly to train the network.\"\"\"\n",
    "    def __init__(self, buffer_size=50000):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        \n",
    "    def add(self, states, actions, rewards, dones):\n",
    "        if len(self.actions) == self.buffer_size:\n",
    "            self.states = self.states[1:]\n",
    "            self.actions = self.actions[1:]\n",
    "            self.rewards = self.rewards[1:]\n",
    "            self.dones = self.dones[1:]\n",
    "\n",
    "        self.states.append(states)\n",
    "        self.actions.append(actions)\n",
    "        self.rewards.append(rewards)\n",
    "        self.dones.append(dones)\n",
    "        \n",
    "    def sample(self, size, previous_states):\n",
    "        samples = np.random.permutation(len(self.actions)-(previous_states-1)) + (previous_states-1)\n",
    "\n",
    "        states = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        states_ = []\n",
    "        dones = []\n",
    "        for i in samples[:size]:\n",
    "            temp = []\n",
    "            for j in range(previous_states):\n",
    "                temp.append(self.states[i - previous_states + j + 1])\n",
    "            states.append(np.dstack(temp))\n",
    "            actions.append(self.actions[i])\n",
    "            rewards.append(self.rewards[i])\n",
    "            states_.append(self.states[i+1])\n",
    "            dones.append(self.dones[i])\n",
    "                \n",
    "        return states, actions, rewards, states_, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateTargetGraph(tfVars,tau):\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
    "        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
    "    return op_holder\n",
    "\n",
    "def updateTarget(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32 #How many experiences to use for each training step.\n",
    "update_freq = 8 #How often to perform a training step.\n",
    "y = .99 #Discount factor on the target Q-values\n",
    "startE = 1 #Starting chance of random action\n",
    "endE = 0.1 #Final chance of random action\n",
    "anneling_steps = 1 #How many steps of training to reduce startE to endE.\n",
    "num_episodes = 100003 #How many episodes of game environment to train network with.\n",
    "pre_train_steps = 20000 #How many steps of random actions before training begins.\n",
    "pre_train_steps_from_Q = False #If true, initialize buffer with steps from Q instead of random actions\n",
    "max_epLength = 5000 #The max allowed length of our episode.\n",
    "load_model = True #Whether to load a saved model.\n",
    "path = \"./dqn/save_data/2048/1/\" #The path to save our model to.\n",
    "h_size = 512 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "tau = 0.0001 #Rate to update target network toward primary network\n",
    "previous_states=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env = gameEnv()\n",
    "tf.reset_default_graph()\n",
    "mainQN = Qnetwork(h_size,previous_states)\n",
    "targetQN = Qnetwork(h_size,previous_states)\n",
    "sess = tf.Session()\n",
    "load = './dqn/save_data/2048/1/model.cptk'\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess,load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAHfCAYAAAB0213WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1bc803db38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.renderDisplay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAHfCAYAAAB0213WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+H9RoxI3KWLntwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1a74269320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    complete = False\n",
    "    iter = 0\n",
    "    env = gameEnv()\n",
    "    r_all = 0\n",
    "    \n",
    "    while(complete == False):\n",
    "        action = sess.run(mainQN.predict, feed_dict={mainQN.imageIn:[env.renderEnv().reshape([84, 84, 1])]})\n",
    "        observation, reward, done = env.step(action)\n",
    "        while(env.checkMove() == False):\n",
    "            a = random.randint(0,3)\n",
    "            observation, reward, done = env.step(a)\n",
    "        \n",
    "        display.clear_output(wait=True)\n",
    "        display.display(env.renderDisplay())\n",
    "        \n",
    "        r_all += reward\n",
    "        iter += 1\n",
    "        if done:\n",
    "#             arr.append(r_all)\n",
    "            complete = True\n",
    "            print(iter)\n",
    "            print(\"Complete\")\n",
    "            print(\"reward: \", r_all)\n",
    "#         time.sleep(.005)\n",
    "    print(\"\\n \\n \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
