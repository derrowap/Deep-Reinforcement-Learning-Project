{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "from IPython import display\n",
    "import time\n",
    "import math\n",
    "import cProfile\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_color(value):\n",
    "    if value <= 0:\n",
    "        return '#cdc1b4'\n",
    "    if value <= 2:\n",
    "        return '#eee4da'\n",
    "    if value <= 4:\n",
    "        return '#ede0c8'\n",
    "    if value <= 8:\n",
    "        return '#f2b179'\n",
    "    if value <= 16:\n",
    "        return '#f59563'\n",
    "    if value <= 32:\n",
    "        return '#f67c5f'\n",
    "    if value <= 64:\n",
    "        return '#f65e3b'\n",
    "    if value <= 128:\n",
    "        return '#edcf72'\n",
    "    if value <= 256:\n",
    "        return '#edcc61'\n",
    "    if value <= 512:\n",
    "        return '#edc850'\n",
    "    if value <= 1024:\n",
    "        return '#edc53f'\n",
    "    return '#ecc02e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class gameEnv():\n",
    "    def __init__(self):\n",
    "        self.size = 4\n",
    "        self.actions = 4\n",
    "        self.a = []\n",
    "        self.rendered = []\n",
    "        self.currReward = 0\n",
    "        self.cumReward = 0\n",
    "        self.reset()\n",
    "        self.won = False\n",
    "        self.movement = False\n",
    "        self.last_action = 0\n",
    "    \n",
    "    def reset(self):\n",
    "        arr = np.array([0 for i in range(16)])\n",
    "        self.a = arr.reshape([4,4])\n",
    "        self.addRandomOpen()\n",
    "        self.renderEnv()\n",
    "        self.currReward = 0\n",
    "        self.cumReward = 0\n",
    "        return self.a\n",
    "        \n",
    "    def addRandomOpen(self):\n",
    "        indices = np.asarray(np.where(self.a == 0)).T\n",
    "        choice = random.choice(indices)\n",
    "        if(np.random.rand(1)<.1):\n",
    "            self.a[choice[0]][choice[1]] = 4\n",
    "        else:\n",
    "            self.a[choice[0]][choice[1]] = 2\n",
    "    \n",
    "    def renderEnv(self):\n",
    "        arr = np.ones([4,4])\n",
    "        for i in range(16):\n",
    "            arr[i//4][i%4] = self.getColor(self.a[i//4][i%4])\n",
    "        return scipy.misc.imresize(arr[:,:],[84,84,1],interp='nearest')\n",
    "        \n",
    "    def getColor(self, val):\n",
    "        if(val == 0):\n",
    "            return 0\n",
    "        return math.log2(val) * 23\n",
    "    \n",
    "    def checkEnd(self):\n",
    "        if(len(np.where(self.a == 0)[0]) == 0):\n",
    "            for i in range(4):\n",
    "                self.move(i)\n",
    "                if(checkMove() == True):\n",
    "                    return False\n",
    "            return True\n",
    "#         if(len(np.where(self.a == 2048)[0]) != 0):\n",
    "#             if(self.won == False):\n",
    "#                 print(\"won the game!\")\n",
    "#                 self.won = True\n",
    "#             return True\n",
    "        return False\n",
    "    \n",
    "    # 0 - up, 1 - down, 2 - left, 3 - right\n",
    "    def move(self, action):\n",
    "        if(action == 0):\n",
    "            self.a = np.rot90(self.a,1)\n",
    "            self.a = self.mergeLeft(self.a)\n",
    "            self.a = np.rot90(self.a,3)\n",
    "        elif(action ==1):\n",
    "            self.a = np.rot90(self.a,3)\n",
    "            self.a = self.mergeLeft(self.a)\n",
    "            self.a = np.rot90(self.a,1)\n",
    "        elif(action == 2):\n",
    "            self.a = self.mergeLeft(self.a)\n",
    "        elif(action == 3):\n",
    "            self.a = np.rot90(self.a,2)\n",
    "            self.a = self.mergeLeft(self.a)\n",
    "            self.a = np.rot90(self.a,2)        \n",
    "        \n",
    "        if(self.movement == True):\n",
    "            self.addRandomOpen()\n",
    "            \n",
    "        return self.checkEnd()\n",
    "                        \n",
    "    def step(self, action):\n",
    "        self.last_action = action\n",
    "        done = self.move(action)\n",
    "        return self.renderEnv(),self.currReward,done\n",
    "    \n",
    "    def checkMove(self):\n",
    "        return self.movement\n",
    "        \n",
    "    def mergeLeft(self, arr):\n",
    "        self.currReward = 0\n",
    "        self.movement = False\n",
    "        for i in range(4):\n",
    "            for j in range(1, 4):\n",
    "                stop = 0\n",
    "                if arr[i][j] != 0:\n",
    "                    for k in range(stop, j):\n",
    "                        if(arr[i][k] == arr[i][j]):\n",
    "                            arr[i][k] = arr[i][k] * 2\n",
    "                            arr[i][j] = 0\n",
    "                            self.currReward += arr[i][k]\n",
    "                            stop = j\n",
    "                            self.movement = True\n",
    "                            break\n",
    "                        elif(arr[i][k] == 0):\n",
    "                            arr[i][k] = arr[i][j]\n",
    "                            arr[i][j] = 0\n",
    "                            self.movement = True\n",
    "                            break\n",
    "                            \n",
    "        self.cumReward += self.currReward\n",
    "        return arr\n",
    "    \n",
    "    def renderDisplay(self):\n",
    "        size_of_image = 8\n",
    "        font_size = 20\n",
    "        fig, ax = plt.subplots(figsize=(size_of_image+2, size_of_image))\n",
    "\n",
    "        for x in range(0, 4):\n",
    "            for y in range(0, 4):\n",
    "                ax.broken_barh([(x, 1)],\n",
    "                               (y, 1),\n",
    "                               facecolors=get_color(self.a[y][x]))\n",
    "                if(self.a[y][x] != 0):\n",
    "                    ax.annotate(str(self.a[y][x]), (x, y),\n",
    "                                xytext=((2*x + 1)/2, (2*y + 1) / 2),\n",
    "                                fontsize=font_size,\n",
    "                                horizontalalignment='center',\n",
    "                                verticalalignment='center')\n",
    "\n",
    "        # set range of plot grid\n",
    "        ax.set_ylim(4, 0)\n",
    "        ax.set_xlim(0, 5)\n",
    "\n",
    "        if self.last_action == 0:\n",
    "            # up\n",
    "            plt.arrow(4.5, 2.2, 0.0, -0.4, fc=\"k\", ec=\"k\", head_width=0.1, head_length=0.1)\n",
    "        elif self.last_action == 1:\n",
    "            # down\n",
    "            plt.arrow(4.5, 1.8, 0.0, 0.4, fc=\"k\", ec=\"k\", head_width=0.1, head_length=0.1)\n",
    "        elif self.last_action == 2:\n",
    "            # left\n",
    "            plt.arrow(4.8, 2.0, -0.4, 0.0, fc=\"k\", ec=\"k\", head_width=0.1, head_length=0.1)\n",
    "        elif self.last_action == 3:\n",
    "            # right\n",
    "            plt.arrow(4.3, 2.0, 0.4, 0.0, fc=\"k\", ec=\"k\", head_width=0.1, head_length=0.1)\n",
    "\n",
    "        ax.annotate(\"Score:\", (1, 1), xytext=(4.5, 0.5), fontsize=20,\n",
    "                   horizontalalignment='center', verticalalignment='center')\n",
    "        ax.annotate(str(self.cumReward), (1, 1), xytext=(4.5, 0.9), fontsize=20,\n",
    "                    horizontalalignment='center', verticalalignment='center')    \n",
    "\n",
    "        plt.axis('off')\n",
    "        ax.grid(True)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self,h_size,prev_states):        \n",
    "        #The network recieves a frame from the game, flattened into an array.\n",
    "        #It then resizes it and processes it through four convolutional layers.\n",
    "        self.imageIn = tf.placeholder(shape=[None,84,84,1],dtype=tf.float32)\n",
    "        self.conv1 = tf.contrib.layers.convolution2d( \\\n",
    "            inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n",
    "        self.conv2 = tf.contrib.layers.convolution2d( \\\n",
    "            inputs=self.conv1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding='VALID', biases_initializer=None)\n",
    "        self.conv3 = tf.contrib.layers.convolution2d( \\\n",
    "            inputs=self.conv2,num_outputs=64,kernel_size=[3,3],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        self.conv4 = tf.contrib.layers.convolution2d( \\\n",
    "            inputs=self.conv3,num_outputs=512,kernel_size=[7,7],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        \n",
    "        #We take the output from the final convolutional layer and split it into separate advantage and value streams.\n",
    "        self.streamAC,self.streamVC = tf.split(3,2,self.conv4)\n",
    "        self.streamA = tf.contrib.layers.flatten(self.streamAC)\n",
    "        self.streamV = tf.contrib.layers.flatten(self.streamVC)\n",
    "        self.AW = tf.Variable(tf.random_normal([h_size//2,env.actions]))\n",
    "        self.VW = tf.Variable(tf.random_normal([h_size//2,1]))\n",
    "        self.Advantage = tf.matmul(self.streamA,self.AW)\n",
    "        self.Value = tf.matmul(self.streamV,self.VW)\n",
    "        \n",
    "        #Then combine them together to get our final Q-values.\n",
    "        self.Qout = self.Value + tf.sub(self.Advantage,tf.reduce_mean(self.Advantage,reduction_indices=1,keep_dims=True))\n",
    "        self.predict = tf.argmax(self.Qout,1)\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions,env.actions,dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(tf.mul(self.Qout, self.actions_onehot), reduction_indices=1)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        self.loss = tf.reduce_mean(self.td_error)\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    \"\"\"Used to store experiences and samples randomly to train the network.\"\"\"\n",
    "    def __init__(self, buffer_size=50000):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        \n",
    "    def add(self, states, actions, rewards, dones):\n",
    "        if len(self.actions) == self.buffer_size:\n",
    "            self.states = self.states[1:]\n",
    "            self.actions = self.actions[1:]\n",
    "            self.rewards = self.rewards[1:]\n",
    "            self.dones = self.dones[1:]\n",
    "\n",
    "        self.states.append(states)\n",
    "        self.actions.append(actions)\n",
    "        self.rewards.append(rewards)\n",
    "        self.dones.append(dones)\n",
    "        \n",
    "    def sample(self, size, previous_states):\n",
    "        samples = np.random.permutation(len(self.actions)-(previous_states-1)) + (previous_states-1)\n",
    "\n",
    "        states = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        states_ = []\n",
    "        dones = []\n",
    "        for i in samples[:size]:\n",
    "            temp = []\n",
    "            for j in range(previous_states):\n",
    "                temp.append(self.states[i - previous_states + j + 1])\n",
    "            states.append(np.dstack(temp))\n",
    "            actions.append(self.actions[i])\n",
    "            rewards.append(self.rewards[i])\n",
    "            states_.append(self.states[i+1])\n",
    "            dones.append(self.dones[i])\n",
    "                \n",
    "        return states, actions, rewards, states_, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateTargetGraph(tfVars,tau):\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
    "        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
    "    return op_holder\n",
    "\n",
    "def updateTarget(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32 #How many experiences to use for each training step.\n",
    "update_freq = 8 #How often to perform a training step.\n",
    "y = .99 #Discount factor on the target Q-values\n",
    "startE = 1 #Starting chance of random action\n",
    "endE = 0.1 #Final chance of random action\n",
    "anneling_steps = 1 #How many steps of training to reduce startE to endE.\n",
    "num_episodes = 100003 #How many episodes of game environment to train network with.\n",
    "pre_train_steps = 20000 #How many steps of random actions before training begins.\n",
    "pre_train_steps_from_Q = False #If true, initialize buffer with steps from Q instead of random actions\n",
    "max_epLength = 5000 #The max allowed length of our episode.\n",
    "load_model = True #Whether to load a saved model.\n",
    "path = \"./dqn/save_data/2048/1/\" #The path to save our model to.\n",
    "h_size = 512 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "tau = 0.0001 #Rate to update target network toward primary network\n",
    "previous_states=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env = gameEnv()\n",
    "tf.reset_default_graph()\n",
    "mainQN = Qnetwork(h_size,previous_states)\n",
    "targetQN = Qnetwork(h_size,previous_states)\n",
    "sess = tf.Session()\n",
    "load = './dqn/save_data/2048/1/model.cptk'\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess,load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzsAAAKaCAYAAAAZGEfQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7ca85529b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.renderDisplay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-93f8323ea1c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mr_all\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-ee804e09a08c>\u001b[0m in \u001b[0;36mrenderDisplay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/derrowap/anaconda3/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \"\"\"\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/derrowap/anaconda3/lib/python3.5/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfigure_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mshow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/derrowap/anaconda3/lib/python3.5/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(*objs, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/derrowap/anaconda3/lib/python3.5/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m/home/derrowap/anaconda3/lib/python3.5/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/derrowap/anaconda3/lib/python3.5/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/derrowap/anaconda3/lib/python3.5/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/derrowap/anaconda3/lib/python3.5/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/derrowap/anaconda3/lib/python3.5/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2178\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m                     \u001b[0mdryrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2180\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2181\u001b[0m                 \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cachedRenderer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2182\u001b[0m                 \u001b[0mbbox_inches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/derrowap/anaconda3/lib/python3.5/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0m_png\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    complete = False\n",
    "    iter = 0\n",
    "    env = gameEnv()\n",
    "    r_all = 0\n",
    "    \n",
    "    while(complete == False):\n",
    "        action = sess.run(mainQN.predict, feed_dict={mainQN.imageIn:[env.renderEnv().reshape([84, 84, 1])]})\n",
    "        observation, reward, done = env.step(action)\n",
    "        while(env.checkMove() == False):\n",
    "            a = random.randint(0,3)\n",
    "            observation, reward, done = env.step(a)\n",
    "        \n",
    "        display.clear_output(wait=True)\n",
    "        display.display(env.renderDisplay())\n",
    "        \n",
    "        r_all += reward\n",
    "        iter += 1\n",
    "        if done:\n",
    "#             arr.append(r_all)\n",
    "            complete = True\n",
    "            print(iter)\n",
    "            print(\"Complete\")\n",
    "            print(\"reward: \", r_all)\n",
    "#         time.sleep(.005)\n",
    "    print(\"\\n \\n \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
